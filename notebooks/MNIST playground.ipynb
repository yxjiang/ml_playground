{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# hyper-parameters\n",
    "input_features = 784\n",
    "num_classes = 10\n",
    "num_epoch = 1\n",
    "batch_size = 100\n",
    "learning_rate = 0.002\n",
    "l1_weight = 0.001\n",
    "l2_weight = 0.001\n",
    "\n",
    "# load dataset\n",
    "train_data = torchvision.datasets.MNIST(root='/tmp/data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = torchvision.datasets.MNIST(root='/tmp/data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# initiate data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a logistic regression\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_features, num_classes, num_epoch, learning_rate, l1_weight=0, l2_weight=0):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.model = nn.Linear(input_features, num_classes)\n",
    "        self.input_features = input_features\n",
    "        self.num_epoch = num_epoch\n",
    "        self.learning_rate = learning_rate\n",
    "        self.l1_weight = l1_weight\n",
    "        self.l2_weight = l2_weight\n",
    "            \n",
    "    def forward(self, instances):\n",
    "        \"\"\"\n",
    "        Predict the label with given training instance batch.\n",
    "        \"\"\"\n",
    "        instances = instances.reshape(-1, self.input_features).to(device)\n",
    "        output = self.model(instances).to(device)  # tensor with dim [batch_size, 10] \n",
    "        return output\n",
    "#         return torch.max(output.data, 1)[1]  # idx of the max element for each instance indicates the class\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, model_name='logistic_regression.model', num_epoch=5, output_log_freq=0):\n",
    "    \"\"\"\n",
    "    Train the model with given train_loader. Save the model if model name specified.\n",
    "    \"\"\"\n",
    "    total = len(train_loader)\n",
    "    l1_weight = model.l1_weight if hasattr(model, \"l1_weight\") else 0\n",
    "    l2_weight = model.l2_weight if hasattr(model, \"l2_weight\") else 0\n",
    "    if os.path.exists(model_name):\n",
    "        print(\"load model\")\n",
    "        model.load_state_dict(torch.load(model_name, map_location=device))\n",
    "    \n",
    "    for e in range(num_epoch):\n",
    "        for i, (instances, labels) in enumerate(train_loader):\n",
    "            instances = instances.reshape(-1, model.input_features).to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Forward\n",
    "            output = model(instances)\n",
    "            # Calculate loss\n",
    "            params = torch.cat([x.view(-1) for x in model.parameters()])\n",
    "            loss = criterion(output, labels)\n",
    "            if l1_weight > 0 and l2_weight > 0:\n",
    "                l1_loss = 0 if model.l1_weight == 0 else torch.norm(params, 1)\n",
    "                l2_loss = 0 if model.l2_weight == 0 else torch.norm(params, 2)\n",
    "                loss += l1_weight * l1_loss + l2_weight * l2_loss\n",
    "            # Update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if output_log_freq and (i + 1) % output_log_freq == 0:\n",
    "                print('Epoch %d/%d, trained %d/%d instances, Logloss: %.5f' % \n",
    "                        (e, model.num_epoch, i + 1, total, loss.item()))\n",
    "    if model_name:\n",
    "        print(\"write model\")\n",
    "        torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n",
      "Epoch 0/1, trained 100/600 instances, Logloss: 0.82282\n",
      "Epoch 0/1, trained 200/600 instances, Logloss: 0.77052\n",
      "Epoch 0/1, trained 300/600 instances, Logloss: 0.71091\n",
      "Epoch 0/1, trained 400/600 instances, Logloss: 0.74702\n",
      "Epoch 0/1, trained 500/600 instances, Logloss: 0.67888\n",
      "Epoch 0/1, trained 600/600 instances, Logloss: 0.81556\n",
      "write model\n",
      "Accuracy: 8805/10000\n"
     ]
    }
   ],
   "source": [
    "# Train LR\n",
    "lr = LogisticRegression(input_features, num_classes, num_epoch, learning_rate, l1_weight, l2_weight).to(device)\n",
    "\n",
    "# train the model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_optimizer = torch.optim.SGD(lr.parameters(), lr=lr.learning_rate)\n",
    "\n",
    "        \n",
    "train(lr, criterion, lr_optimizer, train_loader, num_epoch=1, output_log_freq=100)\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "correct, total = 0, 0\n",
    "for images, labels in test_loader:\n",
    "    total += labels.size(0)\n",
    "    predicted = lr.forward(images)\n",
    "    correct += (torch.max(predicted, 1)[1] == labels.to(device)).sum()\n",
    "\n",
    "print('Accuracy: %d/%d' % (correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n",
      "conv1.weight \t torch.Size([6, 1, 3, 3])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([16, 6, 3, 3])\n",
      "conv2.bias \t torch.Size([16])\n",
      "fc1.weight \t torch.Size([120, 400])\n",
      "fc1.bias \t torch.Size([120])\n",
      "fc2.weight \t torch.Size([60, 120])\n",
      "fc2.bias \t torch.Size([60])\n",
      "fc3.weight \t torch.Size([10, 60])\n",
      "fc3.bias \t torch.Size([10])\n",
      "[torch.Size([6, 1, 3, 3]), torch.Size([6]), torch.Size([16, 6, 3, 3]), torch.Size([16]), torch.Size([120, 400]), torch.Size([120]), torch.Size([60, 120]), torch.Size([60]), torch.Size([10, 60]), torch.Size([10])]\n"
     ]
    }
   ],
   "source": [
    "# Simple CNN model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(in_features=400, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.fc3 = nn.Linear(in_features=60, out_features=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=(2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=2)\n",
    "        x = x.view(-1, self.num_flat_features(x))  # change the shape to \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # (1, 10)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        sizes = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in sizes:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "# Inspect the net structure\n",
    "net = Net(num_classes)\n",
    "print(net)\n",
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n",
    "print([param.shape for param in list(net.parameters())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n",
      "Epoch 0/5, trained 100/600 instances, Logloss: 0.09263\n",
      "Epoch 0/5, trained 200/600 instances, Logloss: 0.05441\n",
      "Epoch 0/5, trained 300/600 instances, Logloss: 0.06278\n",
      "Epoch 0/5, trained 400/600 instances, Logloss: 0.04827\n",
      "Epoch 0/5, trained 500/600 instances, Logloss: 0.02453\n",
      "Epoch 0/5, trained 600/600 instances, Logloss: 0.05710\n",
      "Epoch 1/5, trained 100/600 instances, Logloss: 0.12094\n",
      "Epoch 1/5, trained 200/600 instances, Logloss: 0.07699\n",
      "Epoch 1/5, trained 300/600 instances, Logloss: 0.10024\n",
      "Epoch 1/5, trained 400/600 instances, Logloss: 0.13632\n",
      "Epoch 1/5, trained 500/600 instances, Logloss: 0.06573\n",
      "Epoch 1/5, trained 600/600 instances, Logloss: 0.06864\n",
      "Epoch 2/5, trained 100/600 instances, Logloss: 0.03251\n",
      "Epoch 2/5, trained 200/600 instances, Logloss: 0.03139\n",
      "Epoch 2/5, trained 300/600 instances, Logloss: 0.07524\n",
      "Epoch 2/5, trained 400/600 instances, Logloss: 0.02139\n",
      "Epoch 2/5, trained 500/600 instances, Logloss: 0.03631\n",
      "Epoch 2/5, trained 600/600 instances, Logloss: 0.05876\n",
      "Epoch 3/5, trained 100/600 instances, Logloss: 0.02208\n",
      "Epoch 3/5, trained 200/600 instances, Logloss: 0.05156\n",
      "Epoch 3/5, trained 300/600 instances, Logloss: 0.02361\n",
      "Epoch 3/5, trained 400/600 instances, Logloss: 0.05189\n",
      "Epoch 3/5, trained 500/600 instances, Logloss: 0.05193\n",
      "Epoch 3/5, trained 600/600 instances, Logloss: 0.05271\n",
      "Epoch 4/5, trained 100/600 instances, Logloss: 0.07738\n",
      "Epoch 4/5, trained 200/600 instances, Logloss: 0.07485\n",
      "Epoch 4/5, trained 300/600 instances, Logloss: 0.05766\n",
      "Epoch 4/5, trained 400/600 instances, Logloss: 0.13749\n",
      "Epoch 4/5, trained 500/600 instances, Logloss: 0.04172\n",
      "Epoch 4/5, trained 600/600 instances, Logloss: 0.05658\n"
     ]
    }
   ],
   "source": [
    "# Train MNIST\n",
    "net_criterion = nn.CrossEntropyLoss()\n",
    "net_optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate / 10)\n",
    "\n",
    "\n",
    "def train_net(model, criterion, optimizer, train_loader, model_name='net.model', num_epoch=5, output_log_freq=0):\n",
    "    \"\"\"\n",
    "    Train the model with given train_loader. Save the model if model name specified.\n",
    "    \"\"\"\n",
    "    total = len(train_loader)\n",
    "    if os.path.exists(model_name):\n",
    "        print(\"load model\")\n",
    "        model.load_state_dict(torch.load(model_name, map_location=device))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for e in range(num_epoch):\n",
    "        for i, (instances, labels) in enumerate(train_loader):\n",
    "            instances = instances.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Forward\n",
    "            output = model(instances)\n",
    "            # Calculate loss\n",
    "            loss = criterion(output, labels)\n",
    "            # Update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if output_log_freq and (i + 1) % output_log_freq == 0:\n",
    "                print('Epoch %d/%d, trained %d/%d instances, Logloss: %.5f' % \n",
    "                        (e, num_epoch, i + 1, total, loss.item()))\n",
    "    if model_name is not None:\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "                \n",
    "train_net(net, net_criterion, net_optimizer, train_loader, model_name=\"net.model\", num_epoch=5, output_log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9768/10000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "correct, total = 0, 0\n",
    "for images, labels in test_loader:\n",
    "    total += labels.size(0)\n",
    "    predicted = net(images.to(device))\n",
    "    correct += (torch.max(predicted, 1)[1] == labels.to(device)).sum()\n",
    "\n",
    "print('Accuracy: %d/%d' % (correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1797,  0.6996,  0.1432, -1.7373,  1.5378,  0.5873,  2.2067, -0.9361,\n",
      "         -1.9889, -0.5158],\n",
      "        [-1.3159,  0.2482, -0.4371,  0.4883,  1.0038, -1.2690,  0.9729,  1.5214,\n",
      "         -0.8506, -0.8907],\n",
      "        [ 1.9925, -0.9771, -0.2337, -0.3260,  0.1440, -0.0028,  0.5881, -0.7125,\n",
      "         -0.9722,  0.6373],\n",
      "        [ 0.4294,  0.1880, -0.2478,  0.1346, -0.2038, -2.7212,  0.7447, -0.2624,\n",
      "          0.7781,  0.9440],\n",
      "        [-1.3857,  1.0920, -0.2592, -0.9410, -0.6755, -0.0675,  1.1213,  0.6549,\n",
      "          0.0898, -0.7927]])\n",
      "tensor([[0.1399, 0.0865, 0.0496, 0.0076, 0.2001, 0.0773, 0.3906, 0.0169, 0.0059,\n",
      "         0.0257],\n",
      "        [0.0180, 0.0860, 0.0434, 0.1094, 0.1832, 0.0189, 0.1776, 0.3074, 0.0287,\n",
      "         0.0275],\n",
      "        [0.4602, 0.0236, 0.0497, 0.0453, 0.0725, 0.0626, 0.1130, 0.0308, 0.0237,\n",
      "         0.1187],\n",
      "        [0.1166, 0.0916, 0.0593, 0.0869, 0.0619, 0.0050, 0.1599, 0.0584, 0.1653,\n",
      "         0.1951],\n",
      "        [0.0202, 0.2408, 0.0623, 0.0315, 0.0411, 0.0755, 0.2480, 0.1555, 0.0884,\n",
      "         0.0366]])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "output = torch.randn(5, 10)\n",
    "print(output)\n",
    "prob = F.softmax(output, dim=1)\n",
    "print(prob)\n",
    "\n",
    "print(torch.tensor([1]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
