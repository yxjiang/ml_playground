{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a classification that assumes there exists logit relationship between the observable signals (features) $x = (x_1, x_2, ..., x_k)$ and the outcome $y$. Mathematically, it is represented as $\\hat{y}=\\sigma (w^Tx) = \\frac{1}{1 + e^{w^Tx}}$, where w is the weight vector of the model learned against the given training data.\n",
    "\n",
    "**Why use sigmoid function?**\n",
    "\n",
    "Logistic regression is to model the two-class classification problem where there are two possible outcomes (let's say positive and negative). The probability of the positive outcome is p and the probability of the negative outcome is 1 - p. Odds ratio is used to quantify the odds of positive outcomes over the negative outcomes, i.e. $\\frac{p}{1 - p}$ (see the charts for how it looks like).\n",
    "\n",
    "<img src=\"./imgs/odds_ratio.png\" width=\"300\">\n",
    "\n",
    "A property for odds ratio is that the more likely positive outcomes would happen, the higher value it would be. If we take the log of the odds ratio, it would be $\\log(\\frac{p}{1 - p})$ as see below.\n",
    "\n",
    "<img src=\"./imgs/log_odds_ratio.png\" width=\"300\">\n",
    "\n",
    "If we assume there exists linear relationship between the observed signals (features) and the log odds ratio, i.e. $log_odds_ratio{P(y=1|x)} = w^Tx$. Then we would have $y = \\frac{1}{1 - e^{w^Tx}}$.\n",
    "\n",
    "<img src=\"./imgs/logistic_regression.png\">\n",
    "\n",
    "Cross entropy (logloss) is leveraged to quantify the accuracy of the model, i.e. $C = -\\sum_m y^{(m)} \\log{\\hat{y^{(m)}}}$, or $C = -\\sum_m y^{(m)}\\log \\hat{y^{(m)}} - (1 - y)\\log{1 - \\hat{y^{(m)}}}$ for binary classification case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, ndim, l2_weight):\n",
    "        self.W = np.random.randn(ndim + 1, 1)  # ndim + bias\n",
    "        self.l2_weight = l2_weight\n",
    "        \n",
    "    def sigmoid_(self, y):\n",
    "        return 1 / (1 + np.exp(-y))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Conduct prediction for the given batch of X.\"\"\"\n",
    "        bias = np.ones((X.shape[0], 1))  # dim: (n_batch, 1)\n",
    "        X = np.concatenate((bias, X), axis=1)  # dim: (n_batch, d+1)\n",
    "        return self.sigmoid_(self.W.T.dot(X.T).T)  # dim: (n_batch, 1)\n",
    "    \n",
    "    def train(self, X, y, lr):\n",
    "        outputs = self.predict(X)  # dim: (n_batch, 1)\n",
    "        preds_diff = -(np.expand_dims(y, axis=1) - outputs)  # dim: (n_batch, 1)\n",
    "        bias = np.ones((X.shape[0], 1))  # dim: (n_batch, 1)\n",
    "        X_with_bias = np.concatenate((bias, X), axis=1)\n",
    "        dW = np.sum(preds_diff * X_with_bias + self.l2_weight * self.W.T, axis=0)\n",
    "        self.W -= lr * np.expand_dims(dW, axis=1)\n",
    "        return abs(np.sum(preds_diff) / len(preds_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.188\n",
      "loss: 0.008\n",
      "loss: 0.025\n",
      "loss: 0.109\n",
      "loss: 0.008\n",
      "loss: 0.050\n",
      "loss: 0.040\n",
      "loss: 0.008\n",
      "loss: 0.078\n",
      "loss: 0.036\n"
     ]
    }
   ],
   "source": [
    "n_dim, n_batch = 15, 10\n",
    "model = LogisticRegression(ndim=n_dim, l2_weight=0.01)\n",
    "\n",
    "for it in range(1000):\n",
    "    X = np.random.randn(n_batch, n_dim)\n",
    "    y = np.array(np.sum(X, axis=1) >= 1.0, dtype=float)\n",
    "    loss = model.train(X, y, lr=0.05)\n",
    "    if it % 100 == 0:\n",
    "        print('loss: %.3f' % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
